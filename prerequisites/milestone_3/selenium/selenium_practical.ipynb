{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Selenium to scrape data from a website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To use selenium, we need to create an instance that is going to \"drive\" us through the webpage.\n",
    "Here is what it could look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://zoopla.co.uk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have navigated to [Zoopla.co.uk](https://zoopla.co.uk) website. We can search for elements via `Xpath` and can also send mouse and keyboard actions through Selenium as well. Let's recall the challenge we want to solve -- extracting data for 50 houses:\n",
    "* **Sale Price**: Our response variable \n",
    "* Number of Bedrooms \n",
    "* Description \n",
    "* Address\n",
    "\n",
    "We will focus our effort just in the London area, the next cell will take us to the URL corresponding to properties in London:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "URL = \"https://www.zoopla.co.uk/new-homes/property/london/?q=London&results_sort=newest_listings&search_source=new-homes&page_size=25&pn=1&view_type=list\"\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ops... Looks like cookies are blocking us... We need to find a way to get around this. Let's start by using `Xpath` to find the \"Accept All Cookies\" button.\n",
    "\n",
    "*Note, the Zoopla website has a frame in the website. The 'Accept Cookies' is in this frame, so, we have to tell Selenium to access the frame. Usually, if it does not have the frame, you can ignore the `switch_to_frame` method*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cookies to accept\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "URL = \"https://www.zoopla.co.uk/new-homes/property/london/?q=London&results_sort=newest_listings&search_source=new-homes&page_size=25&pn=1&view_type=list\"\n",
    "driver.get(URL)\n",
    "time.sleep(2) # wait for a few seconds so the website does not suspect you are a bot\n",
    "try:\n",
    "    driver.switch_to('gdpr-consent-notice') # This is the id of the frame\n",
    "    accept_cookies_button = driver.find_element(by=By.XPATH, value='//*[@id=\"save\"]') # This is the id of the button\n",
    "    accept_cookies_button.click()\n",
    "except AttributeError:\n",
    "    driver.switch_to('gdpr-consent-notice') # This is the id of the frame\n",
    "    accept_cookies_button = driver.find_element(by=By.XPATH, value='//*[@id=\"save\"]') # This is the id of the button\n",
    "    accept_cookies_button.click()\n",
    "except:\n",
    "    print('No cookies to accept')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we rune the code, the webdriver will go to the website and click the button for us. So, analyse the methods we used:\n",
    "- `find_element()` To make the driver point to the element\n",
    "- `click()` To make the driver click on the element that was pointed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so it is time to start extracting the data we are interested in. Let's extract the price, address, number of bedrooms and the description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, observe the HTML code corresponding to a property:\n",
    "<p align=center><img src=images/Selenium_1.png width=900></p>\n",
    "<figcaption align=\"center\"><cite>Zoopla Website and Corresponding HTML Code</cite></figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get the XPath of that property, it will look like this:\n",
    "\n",
    "`//*[@id=\"listing_60212639\"]`\n",
    "\n",
    "Which is fine if we want to find a single property, but not so great if we want to list all the properties in that page. We will focus on how to get all the properties shortly, for now, let's extract the URL of that property, and extract the information we need. \n",
    "\n",
    "_Note: Zoopa is constantly adding new properties, it is likely that the Xpath changed, so make sure that you are following all the steps and using the correct XPath_\n",
    "\n",
    "Let's take a look again at the HTML code, you will notice that there are some `<a>` tags in the HTML code. Usually, these tags are used to include a hyper reference (`href`). Selenium allows us to get that href, but first we need to locate the `<a>` tag containing the href.\n",
    "\n",
    "So, if you expand one of the `<div>` tags corresponding to a property, you will see something like this:\n",
    "\n",
    "<p align=center><img src=images/Selenium_2.png width=900></p>\n",
    "<figcaption align=\"center\"><cite>Property Div Tag</cite></figcaption>\n",
    "\n",
    "Can you see the `<a>` tag? That is the tag that contains the URL we need. So, let's tell Selenium to extract it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.zoopla.co.uk/new-homes/details/56648054/?search_identifier=91afb4c3755906a0f0140222305f21ae\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome() \n",
    "URL = \"https://www.zoopla.co.uk/new-homes/property/london/?q=London&results_sort=newest_listings&search_source=new-homes&page_size=25&pn=1&view_type=list\"\n",
    "driver.get(URL)\n",
    "time.sleep(2) # Wait a couple of seconds, so the website doesn't suspect you are a bot\n",
    "try:\n",
    "    driver.switch_to_frame('gdpr-consent-notice') # This is the id of the frame\n",
    "    accept_cookies_button = driver.find_element(by=By.XPATH, value='//*[@id=\"save\"]')\n",
    "    accept_cookies_button.click()\n",
    "\n",
    "except AttributeError: # If you have the latest version of Selenium, the code above won't run because the \"switch_to_frame\" is deprecated\n",
    "    driver.switch_to.frame('gdpr-consent-notice') # This is the id of the frame\n",
    "    accept_cookies_button = driver.find_element(by=By.XPATH, value='//*[@id=\"save\"]')\n",
    "    accept_cookies_button.click()\n",
    "\n",
    "except:\n",
    "    pass\n",
    "time.sleep(2)\n",
    "house_property = driver.find_element(by=By.XPATH, value='//*[@id=\"listing_56648054\"]') # Change this xpath with the xpath the current page has in their properties\n",
    "a_tag = house_property.find_element(by=By.TAG_NAME, value='a')\n",
    "link = a_tag.get_attribute('href')\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, now we can visit that link using Selenium. Alternatively, you can also click on the `property` element (`property.click()`) and it will take you to the same page. But you will have to:\n",
    "- Click the element\n",
    "- Sleep\n",
    "- Extract the information\n",
    "- Go back\n",
    "- Sleep\n",
    "- Find the next property \n",
    "- Click\n",
    "- Sleep\n",
    "\n",
    "On the other hand, if you have the links, you can visit them like this:\n",
    "\n",
    "- Extract all the links\n",
    "- Iterate through the list, and for each iteration, visit the corresponding URL\n",
    "- Sleep\n",
    "- Extract the information of the property\n",
    "- Visit the next URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it's up to you, but for many different websites, creating a list with links (which is usually called \"crawler\"), is much more efficient\n",
    "\n",
    "Enough talking (or writing), let's visit the link we extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.get(link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it moved us to the webpage of that property\n",
    "\n",
    "<p align=center><img src=images/Selenium_3.png width=900></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There, you can see the price, address, number of bedrooms, and the description. As always, let's take a look at the XPath corresponding to each property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=center><img src=images/Selenium_4.png width=900></p>\n",
    "<figcaption align=\"center\"><cite>Property Xpath</cite></figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there it is, if you do the same with the number of bedrooms, the address and the description, you should have something like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â£1,405,000\n"
     ]
    }
   ],
   "source": [
    "price = driver.find_element(by=By.XPATH, value='//p[@data-testid=\"listing-price\"]').text\n",
    "print(price)\n",
    "# h3 class = c-eFZDwI\n",
    "address = driver.find_element(by=By.XPATH, value='//').text\n",
    "print(address)\n",
    "# bedrooms = driver.find_element(by=By.XPATH, value='//div[@class=\"c-dkBAiW\"]').text\n",
    "# print(bedrooms)\n",
    "# div_tag = driver.find_element(by=By.XPATH, value='//div[@data-testid=\"truncated_text_container\"]')\n",
    "# span_tag = div_tag.find_element(by=By.XPATH, value='.//span')\n",
    "# description = span_tag.text\n",
    "# print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('AiCore_Testing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3c31baebe60106a56ff341025cd7f91b6e5664397ad521f5422210327a85acf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
